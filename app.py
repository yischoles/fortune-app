"""
Fortune App (Bazi / Four Pillars) â€” Streamlit + OpenAI

Quick start (local):
1) Python 3.10+ recommended
2) pip install -r requirements.txt  (requirements content shown below in this file)
3) Set env var:  export OPENAI_API_KEY=your_key_here
   (optional) export OPENAI_MODEL=gpt-4o-mini  # or gpt-4o / o3-mini, etc.
4) streamlit run app.py

Notes:
- Accurate sexagenary pillars (year/month/day/hour) are computed via the `lunar_python` library.
- If the library isn't available, the app will show a friendly error. Please install dependencies.
- This is an MVP; you can adjust prompt, tone, and feature flags in the CONFIG section below.
"""

from __future__ import annotations
import os
import sys
import json
import traceback
from dataclasses import dataclass
from typing import Dict, Any, Optional, List, Tuple

import streamlit as st

# Try to import lunar_python for precise Bazi computation
try:
    from lunar_python import Solar  # type: ignore
    LUNAR_AVAILABLE = True
except Exception:
    LUNAR_AVAILABLE = False

# Try to import OpenAI SDK (modern)
try:
    from openai import OpenAI  # type: ignore
    OPENAI_SDK = "v1"
except Exception:
    # fallback older import name
    try:
        import openai  # type: ignore
        OPENAI_SDK = "legacy"
    except Exception:
        OPENAI_SDK = None

# ======================
# CONFIG
# ======================
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
SYSTEM_TONE = (
    "ä½ æ˜¯ä¸€ä½ä¸¥è°¨è€Œæ¸©å’Œçš„å…«å­—å‘½ç†å¸ˆï¼Œæ“…é•¿ä»¥ç°ä»£ã€é€šä¿—ã€å¯æ‰§è¡Œçš„å»ºè®®æ¥è§£é‡Šå‘½ç†ã€‚"
    "è¯·ä¿æŒç§¯æã€ä¸­ç«‹ã€é¿å…å®¿å‘½è®ºï¼›è¾“å‡ºéœ€è½åœ°ä¸”ä¸æ¶‰è¿·ä¿¡æå“ã€‚"
)
OUTPUT_SECTIONS = [
    ("æ€»ä½“æ ¼å±€", "æ¦‚è¿°å‘½å±€ç‰¹ç‚¹ã€äº”è¡Œå¼ºå¼±ä¸å¹³è¡¡é‡ç‚¹ã€‚"),
    ("äº‹ä¸šä¸å­¦ä¸š", "ä¼˜åŠ¿ã€é˜»ç¢ã€é€‚åˆçš„æ–¹å‘ä¸å…·ä½“å»ºè®®ã€‚"),
    ("è´¢è¿ä¸è§„åˆ’", "æ­£è´¢/åè´¢å€¾å‘ã€ç†è´¢å»ºè®®ä¸é£é™©æç¤ºã€‚"),
    ("æ„Ÿæƒ…ä¸äººé™…", "æ²Ÿé€šæ–¹å¼ã€æ‹©å‹/æ‹©å¶å»ºè®®ã€å¯æ”¹è¿›ç‚¹ã€‚"),
    ("å¥åº·ä¸ä½œæ¯", "ä½“è´¨å€¾å‘ã€ä½œæ¯é¥®é£Ÿã€è¿åŠ¨å»ºè®®ã€‚"),
    ("å½“ä¸‹å‘¨æœŸ", "ä»¥è¿‘1å¹´â€”3å¹´çš„è¿åŠ¿èŠ‚å¥ç»™å‡ºæ³¨æ„äº‹é¡¹ä¸å…³é”®æœˆä»½/å­£åº¦ã€‚"),
    ("è¡ŒåŠ¨æ¸…å•", "3â€”5æ¡å¯æ‰§è¡Œçš„To-Doï¼Œéœ€å…·ä½“åˆ°è¡Œä¸ºä¸é¢‘ç‡ã€‚")
]

HEAVENLY_STEMS = list("ç”²ä¹™ä¸™ä¸æˆŠå·±åºšè¾›å£¬ç™¸")
EARTHLY_BRANCHES = list("å­ä¸‘å¯…å¯è¾°å·³åˆæœªç”³é…‰æˆŒäº¥")
GAN_TO_WUXING = {
    "ç”²": "æœ¨", "ä¹™": "æœ¨",
    "ä¸™": "ç«", "ä¸": "ç«",
    "æˆŠ": "åœŸ", "å·±": "åœŸ",
    "åºš": "é‡‘", "è¾›": "é‡‘",
    "å£¬": "æ°´", "ç™¸": "æ°´",
}
ZHI_TO_WUXING = {
    "å­": "æ°´", "ä¸‘": "åœŸ", "å¯…": "æœ¨", "å¯": "æœ¨",
    "è¾°": "åœŸ", "å·³": "ç«", "åˆ": "ç«", "æœª": "åœŸ",
    "ç”³": "é‡‘", "é…‰": "é‡‘", "æˆŒ": "åœŸ", "äº¥": "æ°´",
}

@dataclass
class Bazi:
    year: str
    month: str
    day: str
    hour: str

    def to_dict(self) -> Dict[str, str]:
        return {"year": self.year, "month": self.month, "day": self.day, "hour": self.hour}

    def wuxing_summary(self) -> Dict[str, int]:
        counts = {"æœ¨": 0, "ç«": 0, "åœŸ": 0, "é‡‘": 0, "æ°´": 0}
        for pillar in [self.year, self.month, self.day, self.hour]:
            if len(pillar) >= 2:
                gan, zhi = pillar[0], pillar[1]
                counts[GAN_TO_WUXING.get(gan, "")] = counts.get(GAN_TO_WUXING.get(gan, ""), 0) + 1 if GAN_TO_WUXING.get(gan) else counts.get("æœ¨",0)
                counts[ZHI_TO_WUXING.get(zhi, "")] = counts.get(ZHI_TO_WUXING.get(zhi, ""), 0) + 1 if ZHI_TO_WUXING.get(zhi) else counts.get("æœ¨",0)
        return counts


# ======================
# Core: compute Bazi via lunar_python
# ======================

def compute_bazi(year: int, month: int, day: int, hour: int, minute: int = 0) -> Bazi:
    if not LUNAR_AVAILABLE:
        raise RuntimeError(
            "æœªæ£€æµ‹åˆ° `lunar_python`ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–ï¼špip install lunar-python\n"
            "æˆ–åœ¨ç»ˆç«¯æ‰§è¡Œï¼špip install -r requirements.txt"
        )
    # `Solar` expects local time; users should input local birth time.
    solar = Solar.fromYmdHms(year, month, day, hour, minute, 0)
    lunar = solar.getLunar()
    ec = lunar.getEightChar()
    # The library returns strings like 'ç”²å­', 'ä¹™ä¸‘' etc.
    gz_year = ec.getYear()
    gz_month = ec.getMonth()
    gz_day = ec.getDay()
    gz_time = ec.getTime()
    return Bazi(year=gz_year, month=gz_month, day=gz_day, hour=gz_time)


# ======================
# OpenAI client helpers
# ======================

def get_openai_client():
    if OPENAI_SDK == "v1":
        return OpenAI()
    elif OPENAI_SDK == "legacy":
        # create a thin wrapper for legacy style
        class Legacy:
            def __init__(self):
                self.lib = openai
            def chat_complete(self, model: str, messages: List[Dict[str, str]]):
                return self.lib.ChatCompletion.create(model=model, messages=messages)
        return Legacy()
    else:
        raise RuntimeError(
            "æœªæ£€æµ‹åˆ° OpenAI SDKã€‚è¯·å…ˆå®‰è£…ï¼špip install openai"
        )


def call_llm_for_reading(bazi: Bazi, profile: Dict[str, Any]) -> str:
    """Compose the system & user prompts and call the LLM to generate the reading."""
    model = os.getenv("OPENAI_MODEL", DEFAULT_MODEL)
    system_msg = SYSTEM_TONE

    # Prepare brief Wuxing stats for extra context
    wx = bazi.wuxing_summary()

    user_payload = {
        "input_format": {
            "bazi": bazi.to_dict(),
            "wuxing_counts": wx,
            "user_profile": profile,
        },
        "instructions": {
            "style": "ç®€æ´ã€çœŸè¯šã€æ¥åœ°æ°”ã€å¯æ‰§è¡Œï¼Œé¿å…å“å”¬ä¸ç»å¯¹åŒ–ç»“è®º",
            "sections": OUTPUT_SECTIONS,
            "format": "ä½¿ç”¨æœ‰å±‚çº§çš„å°æ ‡é¢˜ä¸é¡¹ç›®ç¬¦å·ï¼›é‡ç‚¹ç»™å‡ºå…·ä½“è¡ŒåŠ¨å»ºè®®",
        }
    }

    # Build messages
    messages = [
        {"role": "system", "content": system_msg},
        {
            "role": "user",
            "content": (
                "è¯·åŸºäºä»¥ä¸‹å…«å­—ä¿¡æ¯è¿›è¡Œå‘½ç†åˆ†æï¼Œå¹¶æŒ‰ç…§ `sections` è¾“å‡ºç»“æ„åŒ–ä¸­æ–‡æŠ¥å‘Šã€‚\n"
                + json.dumps(user_payload, ensure_ascii=False, indent=2)
            ),
        },
    ]

    client = get_openai_client()

    if OPENAI_SDK == "v1":
        resp = client.chat.completions.create(model=model, messages=messages, temperature=0.7)
        return resp.choices[0].message.content.strip()
    else:
        # legacy wrapper path
        resp = client.chat_complete(model=model, messages=messages)
        return resp["choices"][0]["message"]["content"].strip()


# ======================
# Streamlit UI
# ======================

st.set_page_config(page_title="å…«å­—ç®—å‘½ Â· MVP", page_icon="ğŸ”®", layout="centered")
st.title("ğŸ”® å…«å­—ç®—å‘½ Â· MVP")
st.caption("è¾“å…¥å‡ºç”Ÿä¿¡æ¯ï¼Œè‡ªåŠ¨æ’ç›˜å¹¶ç”Ÿæˆç»“æ„åŒ–çš„è¿åŠ¿å»ºè®®ï¼ˆæ•™è‚²å¨±ä¹ç”¨é€”ï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜", expanded=False):
    st.markdown(
        """
        - **å‡†ç¡®æ€§**ï¼šæœ¬å·¥å…·ä½¿ç”¨æƒå¨å†œå†/å¹²æ”¯åº“ `lunar_python` è¿›è¡Œæ’ç›˜ï¼›è¯·å°½é‡æä¾›**å‡ºç”Ÿåœ°æ—¶åŒºå¯¹åº”çš„æœ¬åœ°æ—¶é—´**ã€‚
        - **éšç§**ï¼šæ•°æ®ä»…ç”¨äºç”Ÿæˆæœ¬æ¬¡æŠ¥å‘Šï¼›è‹¥å‹¾é€‰ä¿å­˜ï¼Œå°†å†™å…¥æœ¬åœ°ä¼šè¯çŠ¶æ€ï¼ˆç¤ºä¾‹çº§ï¼‰ã€‚
        - **ç”¨é€”**ï¼šæŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆåŒ»ç–—ã€æ³•å¾‹æˆ–è´¢åŠ¡å»ºè®®ã€‚
        """
    )

with st.form("bazi_form"):
    col1, col2 = st.columns(2)
    with col1:
        name = st.text_input("å§“åï¼ˆå¯é€‰ï¼‰", value="")
        gender = st.selectbox("æ€§åˆ«ï¼ˆå¯é€‰ï¼‰", ["æœªå¡«å†™", "ç”·", "å¥³", "å…¶ä»–"], index=0)
        save_history = st.checkbox("ä¿å­˜åˆ°å†å²è®°å½•ï¼ˆæœ¬åœ°ä¼šè¯ç¤ºä¾‹ï¼‰", value=False)
    with col2:
        birth_date = st.date_input("å‡ºç”Ÿæ—¥æœŸ", help="è¯·é€‰æ‹©é˜³å†ç”Ÿæ—¥")
        birth_time = st.time_input("å‡ºç”Ÿæ—¶é—´")

    addl = st.text_area("è¡¥å……èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šç›®å‰èŒä¸šã€å…³æ³¨çš„é—®é¢˜ï¼ˆäº‹ä¸š/æ„Ÿæƒ…/å¥åº·/è´¢åŠ¡ï¼‰ã€ç›®æ ‡ç­‰â€¦")

    submitted = st.form_submit_button("ç”Ÿæˆè¿åŠ¿æŠ¥å‘Š âœ¨")

if submitted:
    try:
        if not LUNAR_AVAILABLE:
            st.error("æœªæ£€æµ‹åˆ° `lunar_python` ä¾èµ–ï¼Œè¯·å…ˆåœ¨ç¯å¢ƒä¸­å®‰è£…ï¼š`pip install lunar-python`ã€‚")
            st.stop()
        if OPENAI_SDK is None:
            st.error("æœªæ£€æµ‹åˆ° OpenAI SDKï¼Œè¯·å…ˆå®‰è£…ï¼š`pip install openai` å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEYã€‚")
            st.stop()
        if not os.getenv("OPENAI_API_KEY"):
            st.error("æœªè®¾ç½® OPENAI_API_KEYã€‚è¯·åœ¨ç»ˆç«¯æ‰§è¡Œï¼š`export OPENAI_API_KEY=your_key_here` åé‡è¯•ã€‚")
            st.stop()

        y, m, d = birth_date.year, birth_date.month, birth_date.day
        h, minute = birth_time.hour, birth_time.minute

        bz = compute_bazi(y, m, d, h, minute)

        st.subheader("æ’ç›˜ç»“æœï¼ˆå››æŸ±ï¼‰")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("å¹´æŸ±", bz.year)
        c2.metric("æœˆæŸ±", bz.month)
        c3.metric("æ—¥æŸ±", bz.day)
        c4.metric("æ—¶æŸ±", bz.hour)

        wx = bz.wuxing_summary()
        st.write("äº”è¡Œè®¡æ•°ï¼ˆç²—ç•¥ï¼‰ï¼š", wx)

        profile = {
            "name": name,
            "gender": gender,
            "notes": addl.strip(),
        }

        with st.status("æ­£åœ¨ç”Ÿæˆå‘½ç†è§£è¯»â€¦â€¦", expanded=False):
            reading = call_llm_for_reading(bz, profile)

        st.markdown("---")
        st.subheader("å‘½ç†è§£è¯»ä¸å»ºè®®")
        st.write(reading)

        if save_history:
            if "history" not in st.session_state:
                st.session_state["history"] = []
            st.session_state["history"].append({
                "profile": profile,
                "bazi": bz.to_dict(),
                "wuxing": wx,
                "output": reading,
            })

    except Exception as e:
        st.error("å‡ºé”™äº†ï¼š" + str(e))
        st.exception(e)

# History viewer
if "history" in st.session_state and st.session_state["history"]:
    with st.expander("å†å²è®°å½•", expanded=False):
        for i, item in enumerate(reversed(st.session_state["history"])):
            st.markdown(f"**è®°å½• {len(st.session_state['history']) - i}**")
            cols = st.columns(4)
            cols[0].write("å¹´æŸ±:" + item["bazi"]["year"])
            cols[1].write("æœˆæŸ±:" + item["bazi"]["month"])
            cols[2].write("æ—¥æŸ±:" + item["bazi"]["day"])
            cols[3].write("æ—¶æŸ±:" + item["bazi"]["hour"])
            st.write(item["output"])
            st.markdown("---")

# ======================
# Inline requirements for convenience (copy to requirements.txt)
# ======================

REQUIREMENTS = """
openai>=1.0.0
streamlit>=1.33.0
lunar-python>=1.6.5
"""

with st.expander("requirements.txtï¼ˆç‚¹å‡»å±•å¼€ä»¥å¤åˆ¶ï¼‰", expanded=False):
    st.code(REQUIREMENTS, language="text")
